{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The Quick brown fox, jumps over the lazy little dog. Hello World.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Quick',\n",
       " 'brown',\n",
       " 'fox,',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'little',\n",
       " 'dog.',\n",
       " 'Hello',\n",
       " 'World.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " ',',\n",
       " 'jumps',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'little',\n",
       " 'dog',\n",
       " '.',\n",
       " 'Hello',\n",
       " 'World',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('Quick', 'NNP'),\n",
       " ('brown', 'NN'),\n",
       " ('fox', 'NN'),\n",
       " (',', ','),\n",
       " ('jumps', 'VBZ'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lazy', 'JJ'),\n",
       " ('little', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Hello', 'NNP'),\n",
       " ('World', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = word_tokenize(sentence)\n",
    "nltk.pos_tag(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('computer.n.01'), Synset('calculator.n.01')]\n",
      "computer.n.01\n",
      "a machine for performing calculations automatically\n",
      "calculator.n.01\n",
      "an expert at calculation (or at operating calculating machines)\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"computer\")\n",
    "print(syn)\n",
    "print(syn[0].name())\n",
    "print(syn[0].definition())\n",
    " \n",
    "print(syn[1].name())\n",
    "print(syn[1].definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there are two classes of detergents']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"class\")\n",
    "syn[0].examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('communicate.v.02')]\n",
      "[Synset('babble.v.01'), Synset('bark.v.01'), Synset('bay.v.01'), Synset('begin.v.04'), Synset('blubber.v.02'), Synset('blurt_out.v.01'), Synset('bumble.v.03'), Synset('cackle.v.01'), Synset('chatter.v.04'), Synset('chatter.v.05'), Synset('deliver.v.01'), Synset('drone.v.02'), Synset('enthuse.v.02'), Synset('generalize.v.02'), Synset('gulp.v.02'), Synset('hiss.v.03'), Synset('lip_off.v.01'), Synset('mumble.v.01'), Synset('murmur.v.01'), Synset('open_up.v.07'), Synset('peep.v.04'), Synset('rant.v.01'), Synset('rasp.v.02'), Synset('read.v.03'), Synset('shout.v.01'), Synset('sing.v.02'), Synset('slur.v.03'), Synset('snap.v.01'), Synset('snivel.v.01'), Synset('speak_in_tongues.v.01'), Synset('speak_up.v.02'), Synset('swallow.v.04'), Synset('talk_of.v.01'), Synset('tone.v.01'), Synset('tone.v.02'), Synset('troll.v.07'), Synset('verbalize.v.01'), Synset('vocalize.v.05'), Synset('whiff.v.05'), Synset('whisper.v.01'), Synset('yack.v.01')]\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"speak\")[0]\n",
    " \n",
    "print(syn.hypernyms())\n",
    " \n",
    "print(syn.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('evil.n.03.evil')]\n",
      "[Lemma('evil.n.03.evilness')]\n",
      "[Lemma('bad.n.01.bad')]\n",
      "[Lemma('bad.n.01.badness')]\n",
      "[Lemma('bad.a.01.bad')]\n",
      "[Lemma('evil.a.01.evil')]\n",
      "[Lemma('ill.r.01.ill')]\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"good\")\n",
    "for s in syn:\n",
    "    for l in s.lemmas():\n",
    "        if (l.antonyms()):\n",
    "            print(l.antonyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('book.n.01.book')]\n",
      "[Lemma('book.n.02.book'), Lemma('book.n.02.volume')]\n",
      "[Lemma('record.n.05.record'), Lemma('record.n.05.record_book'), Lemma('record.n.05.book')]\n",
      "[Lemma('script.n.01.script'), Lemma('script.n.01.book'), Lemma('script.n.01.playscript')]\n",
      "[Lemma('ledger.n.01.ledger'), Lemma('ledger.n.01.leger'), Lemma('ledger.n.01.account_book'), Lemma('ledger.n.01.book_of_account'), Lemma('ledger.n.01.book')]\n",
      "[Lemma('book.n.06.book')]\n",
      "[Lemma('book.n.07.book'), Lemma('book.n.07.rule_book')]\n",
      "[Lemma('koran.n.01.Koran'), Lemma('koran.n.01.Quran'), Lemma('koran.n.01.al-Qur'an'), Lemma('koran.n.01.Book')]\n",
      "[Lemma('bible.n.01.Bible'), Lemma('bible.n.01.Christian_Bible'), Lemma('bible.n.01.Book'), Lemma('bible.n.01.Good_Book'), Lemma('bible.n.01.Holy_Scripture'), Lemma('bible.n.01.Holy_Writ'), Lemma('bible.n.01.Scripture'), Lemma('bible.n.01.Word_of_God'), Lemma('bible.n.01.Word')]\n",
      "[Lemma('book.n.10.book')]\n",
      "[Lemma('book.n.11.book')]\n",
      "[Lemma('book.v.01.book')]\n",
      "[Lemma('reserve.v.04.reserve'), Lemma('reserve.v.04.hold'), Lemma('reserve.v.04.book')]\n",
      "[Lemma('book.v.03.book')]\n",
      "[Lemma('book.v.04.book')]\n"
     ]
    }
   ],
   "source": [
    "syn = wordnet.synsets(\"book\")\n",
    "for s in syn:\n",
    "    print(s.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
